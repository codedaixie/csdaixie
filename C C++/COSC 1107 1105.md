## Panda学长CS代写
**创始于北美 ｜专注cs全科代写 ｜ 100%原创MOSS查重**

**Panda学长**代写各类程序语言* *: C语言代写, C++代写, 算法作业代写, 数据结构代写, AI/MachineLearning代写, python代写, java代写, matlab代写, 汇编代写, scala代写, SQL/Database代写, racket代写, 安卓/Android代写, IOS/swift代写, racket代写, 网络代写, web代写, OS/操作系统代写, R代写* *

**为什么选择Panda学长CS代写？**

- 我们有经验丰富学历强大的**代写老师**，均毕业于常青藤/清华/北大/北航等顶级CS专业，大部分都是TOP ACMer、LeetCoder, 最快24-48小时即可完成，用技术和耐心帮助客户高效高质量提交作业。
- 我们**价格公道**，绝无高昂的中介费(比中介会便宜很多) 
- 我们的老师都是互相认识的好伙伴，有严格的评价机制，三次差评团队成员就要**强制退出**
- 我们的客服也是由**代写老师轮流担任**，在20分钟内准确高效的评估作业时间和难度，完成后团队有专人负责代码审计。相比于黑中介和个人代写不靠谱，我们团队让您的作业拿到更多分数
- **无限期售后服务**，真正的一站式无忧服务
- 专注留学生编程作业代写,起步于北美，cs业务遍及全球英语国家: [北美CS代写](https://github.com/codedaixie/csdaixie),[美国CS代写](https://github.com/codedaixie/csdaixie),[英国CS代写](https://github.com/codedaixie/csdaixie),[加拿大CS代写](https://github.com/codedaixie/csdaixie),[澳洲CS代写](https://github.com/codedaixie/csdaixie),[新西兰CS代写](https://github.com/codedaixie/csdaixie),[新加坡CS代写](https://github.com/codedaixie/csdaixie),[香港CS代写](https://github.com/codedaixie/csdaixie)

Please feel free to contact us anytime！

**客服24h咨询方式     **微信：cube787**


<img src='https://github.com/codedaixie/csdaixie/blob/main/image/down.png'>
<img src='https://github.com/codedaixie/csdaixie/blob/main/image/logo.png' width='85%'>

### COSC 1107/1105

H = {f(x, θ); θ ∈ Θ}.
and state explicitly what is θ and Θ.
4. [15 Marks] Let H be a class of binary classifiers over a set Z. Let D be an unknown distribution
over X , and let g be a target hypothesis in H. Show that the expected value of LossT (g) over
the choice of T equals LossD(g), namely,
ET LossT (g) = LossD(g).
5. [15 Marks (see details below)] Consider the following dataset.
x1 y
0 1
1 2
2 3
3 2
4 1
Now, suppose that we would like to consider two models.
Model1 : y = β0 + ε,
and
Model2 : y = β1x1 + ε,
where ε ∼ N(0, 1). That is, we consider two linear models Model1 is the constant model and
Model2 is a regular linear model without the intercept.
(a) [5 Marks)] Fit these models tot the data and write the corresponding coefficients. Namely,
fill the following table:
Model β0 β1
Model1 0
Model2
(b) [5 Marks)] Consider the squared error loss, the absolute error loss, and the L1.5 loss. Find
the average loss for each model. Namely, fill the following table:
Model squared error loss absolute error loss L1.5 loss
Model1
Model2
(c) [5 Marks)] Draw a conclusion from the obtained results.
6. [30 Marks (see details below)] Consider the Hitters data-set (given in Hitters.csv). Our
objective is to predict a hitter’s salary via linear models.
(a) [5 Marks)] Load the data-set and replace all categorical values with numbers. (You can
use the LabelEncoder object in Python).
(b) [5 Marks)] Generally, it is better to use OneHotEncoder when dealing with categorical
variables. Justify the usage of LabelEncoder in (a).
2
(c) [20 Marks)] Fit linear regression and report 10-Fold Cross-Validation mean squared error.
7. [10 Marks] Consider a function
f(x) = 3 + x2 − 2sin(x) 1 6 x 6 8.
Write a Crude Monte Carlo algorithm for the estimation of
`
= Z 1 8 f(x) dx,
using N = 10000 sample size. Deliver the 95% confidence interval. Compare the obtained
estimation with the true value ` . 3
